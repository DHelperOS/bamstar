#!/usr/bin/env python3
import json
import random
from datetime import datetime, date, timedelta

# ê¸°ì¡´ auth ì‚¬ìš©ì ID ì½ê¸°
def read_auth_user_ids():
    with open('scripts/large_auth_user_ids.txt', 'r') as f:
        lines = f.readlines()
    
    user_ids = []
    for line in lines:
        line = line.strip()
        if line and line != 'id' and line != '--------------------------------------':
            user_ids.append(line.strip())
    
    return user_ids

KOREAN_SURNAMES = ["ê¹€", "ì´", "ë°•", "ìµœ", "ì •", "ê°•", "ì¡°", "ìœ¤", "ì¥", "ì„"]
KOREAN_MALE_NAMES = ["ë¯¼ì¤€", "ì„œì¤€", "ë„ìœ¤", "ì˜ˆì¤€", "ì‹œìš°", "ì£¼ì›", "í•˜ì¤€", "ì§€í˜¸", "ê±´ìš°", "ìš°ì§„"]
KOREAN_FEMALE_NAMES = ["ì„œìœ¤", "ì„œì—°", "ì§€ìš°", "ì„œí˜„", "ë¯¼ì„œ", "í•˜ì€", "ì§€ìœ ", "ì˜ˆì€", "ì±„ì›", "ì§€ë¯¼"]

BUSINESS_TYPES = {
    "ëª¨ë˜ ë°”": {"pay_min": 3500000, "pay_max": 6500000},
    "í† í¬ ë°”": {"pay_min": 3200000, "pay_max": 5800000}, 
    "ìºì£¼ì–¼ í": {"pay_min": 2800000, "pay_max": 5200000},
    "ê°€ë¼ì˜¤ì¼€": {"pay_min": 2500000, "pay_max": 4800000},
    "ì¹´í˜": {"pay_min": 2300000, "pay_max": 4200000},
    "í…Œë¼í”¼": {"pay_min": 4200000, "pay_max": 8500000}
}

PLACE_NAMES = [
    "ê°•ë‚¨ í”„ë¦¬ë¯¸ì—„ ëª¨ë˜ ë°”", "ì••êµ¬ì • ëŸ­ì…”ë¦¬ í† í¬ ë°”", "ì‹ ì‚¬ë™ VIP ìºì£¼ì–¼ í", "ì²­ë‹´ ê³¨ë“  ê°€ë¼ì˜¤ì¼€", "ì—­ì‚¼ ë‹¤ì´ì•„ëª¬ë“œ ì¹´í˜",
    "ì„œì´ˆ í”Œë˜í‹°ë„˜ í…Œë¼í”¼", "ê°•ë‚¨ì—­ ë¡œì–„ í´ëŸ½", "ì••êµ¬ì •ì—­ ì—˜ë¦¬íŠ¸ ë°”", "ì‹ ë…¼í˜„ í”„ë¼ì„ í", "êµëŒ€ì—­ í¬ë¼ìš´ ì¹´í˜",
    "í™ëŒ€ ë¡œì–„ í† í¬ ë°”", "ìƒìˆ˜ë™ í”„ë¦¬ë¯¸ì—„ í", "í•©ì •ì—­ ëª¨ë˜ ì¹´í˜", "í™ìµëŒ€ ê³¨ë“  ë°”", "ìƒìˆ˜ì—­ ë‹¤ì´ì•„ëª¬ë“œ í´ëŸ½",
    "í™ëŒ€ì…êµ¬ í”Œë˜í‹°ë„˜ ê°€ë¼ì˜¤ì¼€", "ë§ˆí¬êµ¬ í¬ë¦¬ìŠ¤íƒˆ í…Œë¼í”¼", "ìƒìˆ˜ë™ ì—˜ë¦¬íŠ¸ í", "í™ëŒ€ê±°ë¦¬ í”„ë¼ì„ ë°”", "í•©ì •ë™ ë¡œì–„ ì¹´í˜",
    "ê±´ëŒ€ ìŠ¤íƒ€ í", "ì‹ ì´Œ ê³¨ë“  ë°”", "ì´íƒœì› í”„ë¦¬ë¯¸ì—„ í´ëŸ½", "ëª…ë™ ë¡œì–„ ì¹´í˜", "ì¢…ë¡œ ë‹¤ì´ì•„ëª¬ë“œ í† í¬ë°”",
    "ì„ì§€ë¡œ ëª¨ë˜ í", "ë™ëŒ€ë¬¸ í¬ë¦¬ìŠ¤íƒˆ ë°”", "ì„±ìˆ˜ë™ ì•„í‹€ë¦¬ì— ì¹´í˜", "ì†¡íŒŒ ì—˜ë¦¬íŠ¸ ê°€ë¼ì˜¤ì¼€", "ë…¸ì› í”„ë¼ì„ í…Œë¼í”¼"
]

EXISTING_ATTRIBUTES = {
    'MEMBER_STYLE': [
        {"id": 16, "name": "ê¸ì •ì "}, {"id": 17, "name": "í™œë°œí•¨"}, {"id": 18, "name": "ëŒ€í™”ë¦¬ë“œ"},
        {"id": 19, "name": "ì„±ì‹¤í•¨"}, {"id": 20, "name": "ì°¨ë¶„í•¨"}, {"id": 21, "name": "íŒ¨ì…˜ì„¼ìŠ¤"},
        {"id": 22, "name": "ë¦¬ì•¡ì…˜ìš”ì •"}, {"id": 23, "name": "ì¢‹ì€ë¹„ìœ¨"}
    ],
    'INDUSTRY': [
        {"id": 1, "name": "ëª¨ë˜ ë°”"}, {"id": 2, "name": "í† í¬ ë°”"}, {"id": 3, "name": "ìºì£¼ì–¼ í"},
        {"id": 4, "name": "ê°€ë¼ì˜¤ì¼€"}, {"id": 5, "name": "ì¹´í˜"}, {"id": 6, "name": "í…Œë¼í”¼"}
    ],
    'PLACE_FEATURE': [
        {"id": 31, "name": "ê²½ë ¥ììš°ëŒ€"}, {"id": 32, "name": "ê³ ê¸‰ìŠ¤ëŸ¬ìš´"}, {"id": 33, "name": "í…ƒì„¸ì—†ìŒ"},
        {"id": 34, "name": "ê°€ì¡±ê°™ì€"}, {"id": 35, "name": "ì´ˆë³´í™˜ì˜"}, {"id": 36, "name": "í¸ì•ˆí•œ"},
        {"id": 37, "name": "ììœ ë³µì¥"}, {"id": 38, "name": "ì¹œêµ¬ë‘ê°™ì´"}, {"id": 39, "name": "íŒŒí‹°ë¶„ìœ„ê¸°"}
    ]
}

def generate_corrected_large_sql():
    auth_user_ids = read_auth_user_ids()
    
    if len(auth_user_ids) < 80:
        print(f"âŒ auth.usersê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. í˜„ì¬ {len(auth_user_ids)}ëª…, ìµœì†Œ 80ëª… í•„ìš”")
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # SQL í—¤ë”
    sql_content = f"""-- BamStar ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚½ì… (ìˆ˜ì • ë²„ì „)
-- ìƒì„±ì¼: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
-- ìŠ¤íƒ€ 50ëª…, í”Œë ˆì´ìŠ¤ 30ëª…

BEGIN;

-- 1. ìŠ¤íƒ€ ì‚¬ìš©ì 50ëª…
"""
    
    # ìŠ¤íƒ€ ì‚¬ìš©ì ìƒì„±
    star_users = []
    for i in range(50):
        auth_id = auth_user_ids[i]
        surname = random.choice(KOREAN_SURNAMES)
        gender = random.choice(['MALE', 'FEMALE'])
        given_name = random.choice(KOREAN_MALE_NAMES if gender == 'MALE' else KOREAN_FEMALE_NAMES)
        real_name = surname + given_name
        nickname = f"ìŠ¤íƒ€#{i+1}"
        
        star_users.append({
            'auth_id': auth_id,
            'nickname': nickname,
            'real_name': real_name,
            'gender': gender,
            'index': i+1
        })
        
        sql_content += f"""INSERT INTO users (id, nickname, email, phone, role_id, created_at, updated_at)
VALUES ('{auth_id}', '{nickname}', 'bamstar_large{i+1}@example.com', '010-{3000+i:04d}-{random.randint(1000,9999)}', 2, NOW() - INTERVAL '{random.randint(1,180)} days', NOW());
"""
    
    # í”Œë ˆì´ìŠ¤ ì‚¬ìš©ì ìƒì„±
    sql_content += "\n-- 2. í”Œë ˆì´ìŠ¤ ì‚¬ìš©ì 30ëª…\n"
    place_users = []
    for i in range(30):
        auth_id = auth_user_ids[50 + i]
        place_name = random.choice(PLACE_NAMES)
        nickname = f"í”Œë ˆì´ìŠ¤#{i+1}"
        
        place_users.append({
            'auth_id': auth_id,
            'nickname': nickname,
            'place_name': place_name,
            'index': i+1
        })
        
        sql_content += f"""INSERT INTO users (id, nickname, email, phone, role_id, created_at, updated_at)
VALUES ('{auth_id}', '{nickname}', 'bamstar_large{50+i+1}@example.com', '010-{4000+i:04d}-{random.randint(1000,9999)}', 3, NOW() - INTERVAL '{random.randint(1,180)} days', NOW());
"""
    
    # ìŠ¤íƒ€ í”„ë¡œí•„ ìƒì„±
    sql_content += "\n-- 3. ìŠ¤íƒ€ í”„ë¡œí•„ 50ê°œ\n"
    for user in star_users:
        experience = random.choice(['NEWBIE', 'JUNIOR', 'SENIOR', 'PROFESSIONAL'])
        pay_type = random.choice(['TC', 'DAILY', 'MONTHLY'])
        base_pay = {'NEWBIE': 3000000, 'JUNIOR': 4000000, 'SENIOR': 5500000, 'PROFESSIONAL': 7000000}[experience]
        pay_amount = base_pay + random.randint(-500000, 1000000)
        
        image_count = random.randint(1, 3)
        image_urls_str = "ARRAY[" + ", ".join([f"'https://bamstar-profile.s3.amazonaws.com/star_{user['auth_id']}_{j+1}.jpg'" for j in range(image_count)]) + "]"
        
        all_days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']
        working_days = random.sample(all_days, random.randint(3, 6))
        working_days_str = "ARRAY[" + ", ".join([f"'{day}'" for day in working_days]) + "]"
        
        matching_conditions = {
            "preferred_business_types": random.sample(list(BUSINESS_TYPES.keys()), random.randint(2, 4)),
            "work_style_preferences": random.sample(["team_work", "individual", "flexible", "stable"], random.randint(1, 3)),
            "location_flexibility": random.choice(["high", "medium", "low"])
        }
        matching_conditions_json = json.dumps(matching_conditions, ensure_ascii=False).replace("'", "''")
        
        sql_content += f"""INSERT INTO member_profiles (
    user_id, real_name, gender, contact_phone, profile_image_urls, bio,
    experience_level, desired_pay_type, desired_pay_amount, desired_working_days,
    available_from, can_relocate, level, experience_points, title, age, matching_conditions
) VALUES (
    '{user['auth_id']}', '{user['real_name']}', '{user['gender']}', '010-{5000+user['index']:04d}-{random.randint(1000,9999)}',
    {image_urls_str}, '{user['real_name']}ë‹˜ì€ ì—´ì •ì ì¸ ë°¤ì•Œë°” ìŠ¤íƒ€ì…ë‹ˆë‹¤.',
    '{experience}', '{pay_type}', {pay_amount}, {working_days_str},
    '{(date.today() + timedelta(days=random.randint(1, 30))).isoformat()}', {random.choice(['true', 'false'])},
    {random.randint(1, 10)}, {random.randint(0, 5000)}, 'ê²½ë ¥', {random.randint(20, 35)}, '{matching_conditions_json}'
);
"""
    
    # í”Œë ˆì´ìŠ¤ í”„ë¡œí•„ ìƒì„±
    sql_content += "\n-- 4. í”Œë ˆì´ìŠ¤ í”„ë¡œí•„ 30ê°œ\n"
    for user in place_users:
        business_type = random.choice(list(BUSINESS_TYPES.keys()))
        business_info = BUSINESS_TYPES[business_type]
        
        business_number = f"{random.randint(100,999)}-{random.randint(10,99)}-{random.randint(10000,99999)}"
        
        seoul_areas = ["ê°•ë‚¨êµ¬", "ì„œì´ˆêµ¬", "ë§ˆí¬êµ¬", "ìš©ì‚°êµ¬", "ì¤‘êµ¬", "ì¢…ë¡œêµ¬"]
        area = random.choice(seoul_areas)
        address = f"ì„œìš¸íŠ¹ë³„ì‹œ {area} ì—­ì‚¼ë™ {random.randint(1, 999)}-{random.randint(1, 99)}"
        
        offered_min = business_info["pay_min"] + random.randint(-300000, 0)
        offered_max = business_info["pay_max"] + random.randint(0, 500000)
        
        operating_hours = {
            "monday": {"open": "18:00", "close": "02:00"},
            "tuesday": {"open": "18:00", "close": "02:00"},
            "wednesday": {"open": "18:00", "close": "02:00"},
            "thursday": {"open": "18:00", "close": "03:00"},
            "friday": {"open": "18:00", "close": "04:00"},
            "saturday": {"open": "18:00", "close": "04:00"},
            "sunday": {"open": "18:00", "close": "01:00"}
        }
        operating_hours_json = json.dumps(operating_hours, ensure_ascii=False).replace("'", "''")
        
        manager_names = ["ê¹€ë§¤ë‹ˆì €", "ì´ì‹¤ì¥", "ë°•ë§¤ë‹ˆì €", "ìµœì‚¬ì¥", "ìœ¤ë§¤ë‹ˆì €", "ì¥ì›ì¥"]
        manager_name = random.choice(manager_names)
        
        image_count = random.randint(2, 5)
        image_urls_str = "ARRAY[" + ", ".join([f"'https://bamstar-place.s3.amazonaws.com/place_{user['auth_id']}_{j+1}.jpg'" for j in range(image_count)]) + "]"
        
        sql_content += f"""INSERT INTO place_profiles (
    user_id, place_name, business_type, business_number, business_verified,
    address, manager_name, manager_phone, intro, profile_image_urls,
    operating_hours, offered_pay_type, offered_min_pay, offered_max_pay,
    desired_experience_level, created_at, updated_at
) VALUES (
    '{user['auth_id']}', '{user['place_name']}', '{business_type}', '{business_number}', {random.choice(['true', 'false'])},
    '{address}', '{manager_name}', '010-{6000+user['index']:04d}-{random.randint(1000,9999)}',
    '{user['place_name']}ëŠ” {business_type} ì „ë¬¸ ì—…ì²´ì…ë‹ˆë‹¤.',
    {image_urls_str}, '{operating_hours_json}', '{random.choice(['TC', 'ì¼ê¸‰', 'ì›”ê¸‰'])}',
    {offered_min}, {offered_max}, '{random.choice(['ë¬´ê´€', 'ì‹ ì…', 'ì£¼ë‹ˆì–´', 'ì‹œë‹ˆì–´', 'ì „ë¬¸ê°€'])}',
    NOW() - INTERVAL '{random.randint(1, 180)} days', NOW()
);
"""
    
    # ì†ì„± ì—°ê²° ìƒì„±
    sql_content += "\n-- 5. ìŠ¤íƒ€ ì†ì„± ì—°ê²°\n"
    member_styles = EXISTING_ATTRIBUTES['MEMBER_STYLE']
    for user in star_users:
        selected_styles = random.sample(member_styles, random.randint(2, min(4, len(member_styles))))
        for style in selected_styles:
            sql_content += f"INSERT INTO member_attributes_link (member_user_id, attribute_id) VALUES ('{user['auth_id']}', {style['id']});\n"
    
    sql_content += "\n-- 6. í”Œë ˆì´ìŠ¤ ì‚°ì—… ì—°ê²°\n"
    industries = EXISTING_ATTRIBUTES['INDUSTRY']
    industry_by_name = {ind['name']: ind for ind in industries}
    for user in place_users:
        place_business_type = random.choice(list(BUSINESS_TYPES.keys()))
        if place_business_type in industry_by_name:
            industry_id = industry_by_name[place_business_type]['id']
            sql_content += f"INSERT INTO place_industries (place_user_id, attribute_id) VALUES ('{user['auth_id']}', {industry_id});\n"
    
    sql_content += "\n-- 7. í”Œë ˆì´ìŠ¤ íŠ¹ì„± ì—°ê²°\n"
    place_features = EXISTING_ATTRIBUTES['PLACE_FEATURE']
    for user in place_users:
        selected_features = random.sample(place_features, random.randint(2, min(4, len(place_features))))
        for feature in selected_features:
            sql_content += f"INSERT INTO place_attributes_link (place_user_id, attribute_id) VALUES ('{user['auth_id']}', {feature['id']});\n"
    
    sql_content += """
COMMIT;

-- ê²€ì¦ ì¿¼ë¦¬
SELECT 'Total Users' as type, COUNT(*) as count FROM users WHERE email LIKE 'bamstar_large%@example.com';
SELECT 'Stars' as type, COUNT(*) as count FROM member_profiles mp JOIN users u ON mp.user_id = u.id WHERE u.email LIKE 'bamstar_large%@example.com';
SELECT 'Places' as type, COUNT(*) as count FROM place_profiles pp JOIN users u ON pp.user_id = u.id WHERE u.email LIKE 'bamstar_large%@example.com';
"""
    
    filename = f"corrected_large_bamstar_test_data_{timestamp}.sql"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(sql_content)
    
    print(f"âœ… ìˆ˜ì •ëœ ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° SQL ìƒì„± ì™„ë£Œ: {filename}")
    print(f"ğŸ“Š ìŠ¤íƒ€ 50ëª…, í”Œë ˆì´ìŠ¤ 30ëª…, ì†ì„± ì—°ê²° ~200ê°œ")
    
    return filename

if __name__ == "__main__":
    generate_corrected_large_sql()